% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/Estes_JDE006.R
\name{compute_metrics}
\alias{compute_metrics}
\title{Compute Classification Performance Metrics from Confusion Matrix Counts}
\usage{
compute_metrics(TP, FP, TN, FN)
}
\arguments{
\item{TP}{Numeric scalar. Count of true positives (predicted positive, actually positive).}

\item{FP}{Numeric scalar. Count of false positives (predicted positive, actually negative).}

\item{TN}{Numeric scalar. Count of true negatives (predicted negative, actually negative).}

\item{FN}{Numeric scalar. Count of false negatives (predicted negative, actually positive).}
}
\value{
A tibble with one row containing the following metrics:
\itemize{
  \item \strong{Sensitivity} (Recall, True Positive Rate): TP / (TP + FN).
  \item \strong{Specificity} (True Negative Rate): TN / (TN + FP).
  \item \strong{Precision} (Positive Predictive Value, PPV): TP / (TP + FP).
  \item \strong{NPV} (Negative Predictive Value): TN / (TN + FN).
  \item \strong{F1} score: harmonic mean of Precision and Sensitivity.
  \item \strong{Accuracy}: (TP + TN) / (TP + TN + FP + FN).
  \item \strong{BalancedAccuracy}: mean of Sensitivity and Specificity.
  \item \strong{YoudenJ}: Sensitivity + Specificity â€“ 1, a threshold-free diagnostic index.
  \item \strong{MCC} (Matthews Correlation Coefficient): correlation-like statistic
        robust to imbalanced classes, with safeguards against overflow/undefined denominators.
}
}
\description{
#' Customized for Estes SIV/HIV rebound study JDE006
}
\details{
This function calculates a standard set of performance metrics given
the raw counts from a binary classification confusion matrix:
True Positives (TP), False Positives (FP), True Negatives (TN),
and False Negatives (FN). It is designed to be robust to small sample
sizes, missing denominators, and potential integer overflow.


All metrics are computed with checks to avoid division by zero or invalid
results. If a denominator is zero, the corresponding metric is returned as
`NA_real_`. The MCC denominator is protected against overflow by computing
on double precision and requiring finiteness and positivity before division.
}
\examples{
# Example confusion matrix counts
TP <- 69; FP <- 59; TN <- 484; FN <- 132
compute_metrics(TP, FP, TN, FN)

# Edge case: zero positives
compute_metrics(TP = 0, FP = 10, TN = 90, FN = 0)

}
\seealso{
[caret::confusionMatrix()] for generating confusion matrices directly.
}
